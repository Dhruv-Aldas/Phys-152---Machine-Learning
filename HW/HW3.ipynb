{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55e522f",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn\n",
    "import torch.nn.functional\n",
    "import torch.optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138dac6",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Let's explore hyperparameter optimization.  We'll do something relatively simple that's actually not far from what most people do to study the effect of hyperparameters on their model.  Let's revisit the neural network we implemented to learn the $\\sin$ function in our `NeuralNetworks2` notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "x_train = 6 * torch.rand((1000, 1)) - 3\n",
    "y_train = torch.sin(x_train)\n",
    "x_test = 6 * torch.rand((100, 1)) - 3\n",
    "y_test = torch.sin(x_test)\n",
    "plt.plot(x_test.numpy(), y_test.numpy(), '.', label='TEST')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d7ce5",
   "metadata": {},
   "source": [
    "Wrap the tensors into Dataset objects to simplify passing them around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec486c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "xy_test = torch.utils.data.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2429c8",
   "metadata": {},
   "source": [
    "Create (and save) the baseline model to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ed122",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "baseline = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 20),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(20, 25),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(25, 1),\n",
    ")\n",
    "torch.save(baseline.state_dict(), 'baseline.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda4e2f9",
   "metadata": {},
   "source": [
    "Now, your job: implement the function below to build a train and test loop using hyperparameters specified as function arguments. Your code should produce a single scatter plot showing the TRAIN and TEST loss curves, similar to the ones we produced earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(train_data, test_data, model, loss_fn=torch.nn.MSELoss(), n_epochs=200,\n",
    "          batch_size=200, learning_rate=0.1, momentum=0.9, make_plot=True):\n",
    "    \"\"\"Perform a train and test loop with specified hyperparameters.\n",
    "    \n",
    "    Uses SGD optimization and produces a scatter plot of TRAIN and TEST\n",
    "    loss versus epoch on a log-linear scale.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : torch.utils.data.Dataset\n",
    "        Container for the training input and target tensors to use.\n",
    "    test_data : torch.utils.data.Dataset\n",
    "        Container for the test input and target tensors to use.\n",
    "    model : torch.nn.Module\n",
    "        Neural network model of the data whose parameters will be learned.\n",
    "    loss_fn : callable\n",
    "        Function of (y_out, y_tgt) that calculates the scalar loss to use.\n",
    "        Must support backwards() method.\n",
    "    n_epochs : int\n",
    "        Number of epochs of training to perform.\n",
    "    batch_size : int\n",
    "        Size of each (randomly shuffled) minibatch to use.\n",
    "    learning_rate : float\n",
    "        Learning rate to use for the SGD optimizer.\n",
    "    momentum : float\n",
    "        Momentum to use for the SGD optimizer.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple (train, test) of arrays of loss values after each epoch for\n",
    "        the TRAIN and TEST samples, respectively. Both lists should have\n",
    "        length equal to n_epochs.    \n",
    "    \"\"\"\n",
    "    \n",
    "    losses_train, losses_test = [], []\n",
    "    loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    x_test, y_test = test_data.tensors\n",
    "\n",
    "    # YOUR CODE HERE...  replace the next line with your solution\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    if make_plot:\n",
    "        plt.plot(losses_train, '.', label='TRAIN')\n",
    "        plt.plot(losses_test, '.', label='TEST')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Training Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.yscale('log');\n",
    "    return losses_train, losses_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82803c25",
   "metadata": {},
   "source": [
    "Test your code with the default hyperparameters using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4efda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A correct solution should pass these tests.\n",
    "torch.manual_seed(123)\n",
    "baseline.load_state_dict(torch.load('baseline.pth'))\n",
    "train, test = learn(xy_train, xy_test, baseline)\n",
    "assert train[0] > 0.1 and test[0] > 0.1\n",
    "assert train[60] < 1e-3 and test[60] < 1e-3\n",
    "assert train[-1] < 1e-4 and test[-1] < 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe0309",
   "metadata": {},
   "source": [
    "Run the cell below to establish the same initial state (seed and model parameters) and repeat this learning loop with the optimizer momentum set to zero, to show its effect on the loss curves: large synchronized oscillations in both the TRAIN and TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bddc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "baseline.load_state_dict(torch.load('baseline.pth'))\n",
    "learn(xy_train, xy_test, baseline, momentum=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbc6b2",
   "metadata": {},
   "source": [
    "Now we'll scan different values of the batch size, learning rate, and momentum to find good configurations.  In general it's best to do this by sampling random values of each parameter on any given trial, but for ease of interpretation we'll do it in 1-dimension for a few different sets of configurations.\n",
    "\n",
    "Make plots showing the loss curves for the training data for each of the following sets of configurations:\n",
    "* Learning rate = 0.06, batch size=51, for momenta between 0.79 and 1.0 in steps of 0.05\n",
    "* Momentum=0.9, batch size=51, for learning rates between 0.01 and 0.22 in steps of 0.05\n",
    "* Learning rate = 0.1, momentum=0.9, between 1 and the size of the training set, in steps of 100\n",
    "\n",
    "Some notes:\n",
    "* Make sure to reset the random seed and reload the network before each call to the `learn` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the momentum\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the learning rate\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the batch size\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda676c1",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "Let's play around with convolutional kernels and see if we can make some simple filters to apply to real images.  We'll use the `torchvision` package to transform common image formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7efaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd07e88",
   "metadata": {},
   "source": [
    "The pytorch `Conv2D` function that we used to implement some convolutional layers is a high-level function call, and manages the kernel weights internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With square kernels and equal stride\n",
    "m = torch.nn.Conv2d(16, 33, 3, stride=2)\n",
    "\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = torch.nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "\n",
    "# non-square kernels and unequal stride and with padding and dilation\n",
    "m = torch.nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "\n",
    "# generate some random input:\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "\n",
    "# compute the output:\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89acb88b",
   "metadata": {},
   "source": [
    "We can use the lower-level function `torch.nn.functional.conv2d` to manipulate kernels and tensors directly.  \n",
    "\n",
    "Let's do something simple: let's define a 1-layer 5x5 matrix and convolve it with a 3x3 kernel to produce a 3x3 output feature map.  We'll make the kernel super-simple, the equivalent of an identity matrix for convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5e4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 1\n",
    "h, w = 5, 5\n",
    "x = torch.randn(1, channels, h, w)\n",
    "print(x)\n",
    "weights = torch.tensor([[0., 0., 0.],\n",
    "                        [0., 1., 0.],\n",
    "                        [0., 0., 0.]])\n",
    "weights = weights.view(1, 1, 3, 3)\n",
    "\n",
    "output = torch.nn.functional.conv2d(x, weights)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24451fb1",
   "metadata": {},
   "source": [
    "If we add in some padding, then we can make the output tensor the same size as the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19127745",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.nn.functional.conv2d(x, weights,padding=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6aa179",
   "metadata": {},
   "source": [
    "Of course it's possible to do this for more than just one channel, but that gets a bit tricky, so I'll leave that for you to play with if you want!\n",
    "\n",
    "For now let's just try to do something simple with a one-channel image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df48f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"http://mhance.scipp.ucsc.edu/banana-slug-misty-morehead.jpg\", \"banana_slug.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"banana_slug.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46186bda",
   "metadata": {},
   "source": [
    "We can turn this into a numpy array relatively easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed98e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "npimg=np.asarray(img)\n",
    "plt.imshow(npimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b442d79",
   "metadata": {},
   "source": [
    "Or we can use `torchvision` to turn it into a pytorch tensor, and then check that the tensor gives us back the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgtensor=torchvision.io.read_image(\"banana_slug.jpg\")\n",
    "plt.imshow(torchvision.transforms.functional.to_pil_image(imgtensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b3c2d",
   "metadata": {},
   "source": [
    "Let's make this a grayscale image so we only need to deal with a single channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1598f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grayscaleimage=torchvision.transforms.Grayscale()(img)\n",
    "grayscaleimage.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ac53c",
   "metadata": {},
   "source": [
    "Note that if we try to show this image using `plt.imshow` it will try to color it in for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab410bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscaleimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f533ce5",
   "metadata": {},
   "source": [
    "So force it into grayscale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscaleimage,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f118b",
   "metadata": {},
   "source": [
    "We can make this into a tensor for processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscaleimagetensor=torchvision.transforms.functional.to_tensor(grayscaleimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d994b",
   "metadata": {},
   "source": [
    "Now, your job: \n",
    "* implement a 3x3 kernel that shifts every pixel one step to the right\n",
    "* take the difference between the resulting feature map and the original image\n",
    "* display the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe08f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b9dde",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "This is the problem where you should explore the input dataset that you'll use for your final project.\n",
    "\n",
    "I'll do this for a mock dataset, but you should go through a similar exercise with your dataset.\n",
    "\n",
    "I'm importing data that's been stored in the HDF5 format, using the [h5py](https://docs.h5py.org/en/stable/) python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0abe23",
   "metadata": {},
   "source": [
    "If your data are stored in a different format, then certainly some of the details below will have to change, that's OK!  There are lots of ways to read in CSV files and more complicated file formats into python data structures.\n",
    "\n",
    "If you're using ROOT files (common in high-energy physics), there are also lots of ways to get information from those files into python lists.  If you want to convert a ROOT file into HDF5, you can use [this script](https://github.com/scipp-atlas/mario-mapyde/blob/main/scripts/root2hdf5.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "signalfile='lowlevelAna_stops.hf5'\n",
    "urllib.request.urlretrieve(\"http://mhance.scipp.ucsc.edu/%s\" % signalfile, signalfile)\n",
    "\n",
    "backgrfile='lowlevelAna_ttbar.hf5'\n",
    "urllib.request.urlretrieve(\"http://mhance.scipp.ucsc.edu/%s\" % backgrfile, backgrfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53961dc2",
   "metadata": {},
   "source": [
    "Let's inspect the contents of the HDF5 file just to get a sense for what's there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c169fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(signalfile, 'r') as hdf5file:\n",
    "    print(\"Here are the keys in this file\")\n",
    "    print(hdf5file.keys())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # let's access the first key by its index:\n",
    "    group=hdf5file[list(hdf5file.keys())[0]]\n",
    "    print(\"What type does this key have?\")\n",
    "    print(type(group))\n",
    "    print(\"It's a group, so we'll need to look inside of the group to find the dataset\")\n",
    "    print(group.keys())\n",
    "    data=group[\"lowleveltree\"]\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"These are the fields (features) of the dataset:\")\n",
    "    print(data.dtype.names)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Here are the contents of the first event:\")\n",
    "    print(data[0])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"This is the number of jets (numjet) in all events: \")\n",
    "    print(data[\"numjet\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9517de",
   "metadata": {},
   "source": [
    "Now that we know the format, accessing the data is a bit easier...  let's restrict the list of fields (I'll call them 'branches') we read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3942a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "branches=(\"numjet\",\"numlepton\",\"numbtagjet\",\n",
    "          \"met\",\"metphi\",\n",
    "          \"lepton1pT\",\"lepton1eta\",\"lepton1phi\",\n",
    "          \"lepton2pT\",\"lepton2eta\",\"lepton2phi\",\n",
    "          \"jet1pT\", \"jet1eta\", \"jet1phi\",\"jet1b\",\n",
    "          \"jet2pT\", \"jet2eta\", \"jet2phi\",\"jet2b\",\n",
    "          \"jet3pT\", \"jet3eta\", \"jet3phi\",\"jet3b\",\n",
    "          \"jet4pT\", \"jet4eta\", \"jet4phi\",\"jet4b\",\n",
    "          \"jet5pT\", \"jet5eta\", \"jet5phi\",\"jet5b\",\n",
    "          \"jet6pT\", \"jet6eta\", \"jet6phi\",\"jet6b\")\n",
    "\n",
    "with h5py.File(signalfile, 'r') as hdf5file:\n",
    "    data=hdf5file[list(hdf5file.keys())[0]][\"lowleveltree\"]\n",
    "    num_signal_events=len(data[\"numjet\"])\n",
    "    alldata=data[branches]\n",
    "\n",
    "with h5py.File(backgrfile,'r') as hdf5file:\n",
    "    data=hdf5file[list(hdf5file.keys())[0]][\"lowleveltree\"]\n",
    "    num_backgr_events=len(data[\"numjet\"])\n",
    "    alldata = np.concatenate((alldata,data[branches]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f31d2",
   "metadata": {},
   "source": [
    "We read in the data as fields with a custom format, which is useful for keeping track of what's what, but \n",
    "let's store this as python lists instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e4d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Alldata=[[float(i) for i in j] for j in alldata]\n",
    "print(Alldata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ac585",
   "metadata": {},
   "source": [
    "The `Alldata` variable now contains all of the data for both signal and background events.  Since this will be for a binary classification problem, we want to keep track of which event is which, so we'll construct a `y` list that has 0's and 1's corresponding to whether each event is background (0) or signal (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e799c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate((np.ones (num_signal_events), \n",
    "                    np.zeros(num_backgr_events)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05c9e8",
   "metadata": {},
   "source": [
    "Now we can split our full dataset into training and test samples.  However, remember that the data aren't randomized...  the first N events of `Alldata` are all signal events, and the rest of the events are background events.  So we need to shuffle the data first, then pull out training and test samples of a specific size.  The `scikit learn` toolkit has a handy function that does this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e47301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(Alldata, y, test_size=1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affcf8c7",
   "metadata": {},
   "source": [
    "We can look at the input features for our training dataset.  First let's make a map of the feature name to the feature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_before_scaling={}\n",
    "for b in branches:\n",
    "    X_train_before_scaling[b]=[event[branches.index(b)] for event in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abb8f96",
   "metadata": {},
   "source": [
    "Now plot the data for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,30))\n",
    "fig.tight_layout()\n",
    "for b in range(len(branches)):\n",
    "    ax=fig.add_subplot(9,4,1+b if b<8 else 2+b)\n",
    "    plt.subplots_adjust(hspace=0.3,wspace=0.5)\n",
    "    ax.hist(X_train_before_scaling[branches[b]])\n",
    "    ax.set_xlabel(branches[b])\n",
    "    ax.set_ylabel(\"Events/Bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa55f2",
   "metadata": {},
   "source": [
    "This looks good, but the inputs are all over the place!  Some are strictly positive, some have values in the 1's or 10's while others have values in the 1000's.  This broad range of inputs will likely confuse our network and cause some features to have inappropriate influence on the results.  So we should scale the events for each feature to give a distribution that has mean=0 and variance=1.  We can do this for each feature with the following mapping:\n",
    "\n",
    "$$x \\rightarrow z=\\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "where $x$ is the original value, $z$ is the 'scaled' value, $\\mu$ is the mean of all values of $x$, and $\\sigma$ is the standard deviation of $x$.  This isn't hard to do by hand, but again `scikit learn` provides a handy way to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now scale based on the training data:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e0ce9",
   "metadata": {},
   "source": [
    "Let's make that handy map for the scaled data so we can look at the data by feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbb5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_after_scaling={}\n",
    "for b in branches:\n",
    "    X_train_after_scaling[b]=[event[branches.index(b)] for event in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d929c4a",
   "metadata": {},
   "source": [
    "Print some values just to see what happens to a typical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010df282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_before_scaling[\"met\"][:5])\n",
    "print(X_train_after_scaling[\"met\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7ffda",
   "metadata": {},
   "source": [
    "Now re-draw the features after they've been scaled to see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,30))\n",
    "fig.tight_layout()\n",
    "for b in range(len(branches)):\n",
    "    ax=fig.add_subplot(9,4,1+b if b<8 else 2+b)\n",
    "    plt.subplots_adjust(hspace=0.3,wspace=0.5)\n",
    "    ax.hist(X_train_after_scaling[branches[b]])\n",
    "    ax.set_xlabel(branches[b])\n",
    "    ax.set_ylabel(\"Events/Bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e733f6",
   "metadata": {},
   "source": [
    "These look a lot better!\n",
    "\n",
    "One last thing: we've scaled our training data, but not our test data.  Fortunately the `sc` object we created above will remember the transformation that we applied to the training data, so we can transform the test data in exactly the same way (note this is just `transform`, not `fit_transform`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a452e5",
   "metadata": {},
   "source": [
    "Now do this for your data.  Try to get as far as you can.  Depending on the type of data you're analyzing, there may not be anywhere near as many plots to make as what I have above -- that's OK!  The important thing will be to identify what your features are, and make sure that the feature data are scaled appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd01ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
